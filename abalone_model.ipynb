{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abalone_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wozzin/AI_deeplearning/blob/main/abalone_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8V2Bc5X22N5"
      },
      "source": [
        "def main_execute(epoch_count = 10, mb_size = 2, report = 2, train_ratio = 0.8):\n",
        "    load_dataset()\n",
        "    weight_initial, bias_initial = init_param()\n",
        "    losses_mean_row, accs_mean_row, final_acc = train_and_test(epoch_count,\n",
        "                                                               mb_size, \n",
        "                                                               report, \n",
        "                                                               train_ratio)\n",
        "\n",
        "    return weight_initial, bias_initial, losses_mean_row, accs_mean_row, final_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFH91Flx6URr"
      },
      "source": [
        "def load_dataset():\n",
        "    with open('/content/abalone.csv') as csvfile:\n",
        "    #with open('/content/abalone_mini.csv') as csvfile:\n",
        "        csvreader = csv.reader(csvfile)\n",
        "        next(csvreader)\n",
        "        rows = []\n",
        "        for row in csvreader:\n",
        "            rows.append(row)\n",
        "\n",
        "    global data, input_cnt, output_cnt \n",
        "    \n",
        "    input_cnt, output_cnt = 10, 1\n",
        "    data = np.zeros([len(rows), input_cnt + output_cnt])\n",
        "\n",
        "    for n, row in enumerate(rows):\n",
        "        if row[0] == 'M' : data[n, 0] = 1\n",
        "        if row[0] == 'F' : data[n, 1] = 1\n",
        "        if row[0] == 'I' : data[n, 2] = 1\n",
        "        data[n, 3 : ]= row[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWiocqH18fnq"
      },
      "source": [
        "%run /content/MathUtils.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrnBVlcb5aDX"
      },
      "source": [
        "def init_param():\n",
        "    global weight, bias \n",
        "\n",
        "    weight_initial = []\n",
        "    bias_initial   = []\n",
        "    weight = np.random.normal(RND_MEAN, RND_STD, size = [input_cnt, output_cnt])\n",
        "    bias   = np.zeros([output_cnt])\n",
        "    print(\"Initial Weight Value : \\n{}\".format(weight))\n",
        "    print(\"Initial Bias Value : \\n{}\".format(bias))\n",
        "    weight_initial.append(weight)\n",
        "    bias_initial.append(bias)\n",
        "\n",
        "    return weight_initial, bias_initial"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxV3vkYE-yBZ"
      },
      "source": [
        "def arrange_data(mb_size, train_ratio):\n",
        "    \n",
        "    global shuffle_map, test_begin_index\n",
        "\n",
        "    shuffle_map = np.arange(data.shape[0])\n",
        "    np.random.shuffle(shuffle_map)\n",
        "\n",
        "    mini_batch_step_count = int(data.shape[0] * train_ratio) // mb_size\n",
        "    test_begin_index = mini_batch_step_count * mb_size\n",
        "    return mini_batch_step_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9eObzAiDdGi"
      },
      "source": [
        "def get_test_data():\n",
        "    test_data = data[shuffle_map[test_begin_index:]]\n",
        "    return test_data[ : , : -output_cnt], test_data[ : , -output_cnt : ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMKzk3DREcQ4"
      },
      "source": [
        "def get_train_data(mb_size, n):\n",
        "    if n == 0:\n",
        "        np.random.shuffle(shuffle_map[:test_begin_index])\n",
        "\n",
        "    train_data = data[shuffle_map[mb_size * n : mb_size * (n+1) ]]\n",
        "\n",
        "    return train_data[ : , : -output_cnt], train_data[ : , -output_cnt : ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PGh2UF6IbwD"
      },
      "source": [
        "def train_and_test(epoch_count, mb_size, report, train_ratio):\n",
        "    mini_batch_step_count = arrange_data(mb_size, train_ratio)\n",
        "    test_x, test_y = get_test_data()\n",
        "\n",
        "    losses_mean_row = []\n",
        "    accs_mean_row   = []\n",
        "\n",
        "    for epoch in range(epoch_count):\n",
        "        losses = []\n",
        "        accs   = [] \n",
        "        for n in range(mini_batch_step_count):\n",
        "            train_x, train_y = get_train_data(mb_size, n)\n",
        "            loss, acc = run_train(train_x, train_y)\n",
        "            losses.append(loss)\n",
        "            accs.append(acc)\n",
        "\n",
        "        if report > 0 and (epoch + 1) % report == 0:\n",
        "            acc = run_test(test_x, test_y)\n",
        "            print(\"Epoch {} : Train - Loss = {:.3f}, Accuracy = {:.3f}  / Test - Accuracy = {:.3f}\".\\\n",
        "                  format(epoch + 1, np.mean(losses), np.mean(accs), acc))\n",
        "            \n",
        "        losses_mean = np.mean(losses)\n",
        "        accs_mean   = np.mean(accs) * 100\n",
        "\n",
        "        losses_mean_row.append(losses_mean)\n",
        "        accs_mean_row.append(accs_mean)\n",
        "\n",
        "    final_acc = run_test(test_x, test_y)        \n",
        "    print(\"=\" * 30, \"Final TEST\", \"=\" * 30)\n",
        "    print(\"\\nFinal Accuracy : {:.3f}\".format(final_acc))\n",
        "\n",
        "    return losses_mean_row, accs_mean_row, final_acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHi3YzDvDRsU"
      },
      "source": [
        "def forward_neuralnet(x):\n",
        "    y_hat = np.matmul(x, weight) + bias \n",
        "    return y_hat, x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s2j8IS1D27J"
      },
      "source": [
        "def forward_postproc(y_hat, y):\n",
        "    diff   = y_hat - y\n",
        "    square = np.square(diff)\n",
        "    loss   = np.mean(square)\n",
        "\n",
        "    return loss, diff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMXWsZ8UFC_y"
      },
      "source": [
        "def eval_accuracy(y_hat, y):\n",
        "    mdiff = np.mean(np.abs((y_hat - y) / y))\n",
        "    return 1 - mdiff "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLhluODOKzCQ"
      },
      "source": [
        "def backprop_neuralnet(G_output, x):\n",
        "    global weight, bias \n",
        "\n",
        "    x_transpose = x.transpose()\n",
        "    G_w = np.matmul(x_transpose, G_output)\n",
        "\n",
        "    G_b = np.sum(G_output, axis = 0)\n",
        "\n",
        "    weight -= LEARNING_RATE * G_w\n",
        "    bias   -= LEARNING_RATE * G_b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqwH0g7QqSTQ"
      },
      "source": [
        "def backprop_postproc(diff):\n",
        "    M_N = diff.shape\n",
        "\n",
        "    g_mse_square  = np.ones(M_N) / np.prod(M_N)\n",
        "    g_square_diff = 2 * diff \n",
        "    g_diff_output = 1\n",
        "\n",
        "    G_diff   = g_mse_square * g_square_diff \n",
        "    G_output = g_diff_output * G_diff\n",
        "\n",
        "    return G_output "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP014O4ionAV"
      },
      "source": [
        "def run_train(x, y):\n",
        "    y_hat, aux_nn_x   = forward_neuralnet(x)\n",
        "    loss, aux_pp_diff = forward_postproc(y_hat, y)\n",
        "\n",
        "    accuracy = eval_accuracy(y_hat, y)\n",
        "\n",
        "    G_output = backprop_postproc(aux_pp_diff)\n",
        "    backprop_neuralnet(G_output, aux_nn_x)\n",
        "\n",
        "    return loss, accuracy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixWVHFFLuKgH"
      },
      "source": [
        "def run_test(x,y):\n",
        "    y_hat, _ = forward_neuralnet(x)\n",
        "    accuracy = eval_accuracy(y_hat, y)\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}